#!/usr/bin/env node
"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
const node_fs_1 = require("node:fs");
const n3_1 = require("n3");
const rdf_string_1 = require("rdf-string");
const streamToString = require("stream-to-string");
const yargs_1 = require("yargs");
const helpers_1 = require("yargs/helpers");
const __1 = require("..");
function getQuery(query, file) {
    return __awaiter(this, void 0, void 0, function* () {
        if (query) {
            return query;
        }
        if (file) {
            return (0, node_fs_1.readFileSync)(file, { encoding: 'utf-8' });
        }
        return streamToString(process.stdin);
    });
}
function querySelect(endpoint, fetcher, query) {
    return new Promise((resolve, reject) => {
        fetcher.fetchBindings(endpoint, query).then(bindingsStream => bindingsStream
            .on('data', (bindings) => {
            process.stdout.write(`${JSON.stringify(Object.fromEntries(Object.entries(bindings).map(([key, value]) => [
                key,
                (0, rdf_string_1.termToString)(value),
            ])))}\n`);
        })
            .on('error', reject)
            .on('end', resolve)).catch(reject);
    });
}
function queryAsk(endpoint, fetcher, query) {
    return new Promise((resolve, reject) => {
        fetcher.fetchAsk(endpoint, query)
            .then((answer) => {
            process.stdout.write(`${answer}\n`);
            resolve();
        })
            .catch(reject);
    });
}
function queryConstruct(endpoint, fetcher, query) {
    return new Promise((resolve, reject) => {
        fetcher.fetchTriples(endpoint, query)
            .then(tripleStream => tripleStream
            .on('error', reject)
            .pipe(new n3_1.StreamWriter(__1.SparqlEndpointFetcher.CONTENTTYPE_TURTLE))
            .pipe(process.stdout)
            .on('end', resolve)).catch(reject);
    });
}
function update(endpoint, fetcher, query) {
    return new Promise((resolve, reject) => {
        fetcher.fetchUpdate(endpoint, query).then(() => {
            process.stdout.write('OK\n');
            resolve();
        }).catch(reject);
    });
}
function run(argv) {
    return __awaiter(this, void 0, void 0, function* () {
        const args = yield (0, yargs_1.default)((0, helpers_1.hideBin)(argv), 'Sends a query to a SPARQL endpoint')
            .example('$0 --endpoint https://dbpedia.org/sparql --query \'SELECT * WHERE { ?s ?p ?o } LIMIT 100\'', 'Fetch 100 triples from the DBPedia SPARQL endpoint')
            .example('$0 --endpoint https://dbpedia.org/sparql --file query.rq', 'Run the SPARQL query from query.rq against the DBPedia SPARQL endpoint')
            .example('cat query.rq | $0 --endpoint https://dbpedia.org/sparql', 'Run the SPARQL query from query.rq against the DBPedia SPARQL endpoint')
            .options({
            endpoint: { type: 'string', describe: 'Send the query to this SPARQL endpoint', demandOption: true },
            query: { type: 'string', describe: 'Evaluate the given SPARQL query string' },
            file: { type: 'string', describe: 'Evaluate the SPARQL query in the given file' },
            get: { type: 'boolean', describe: 'Send query via HTTP GET instead of POST', default: false },
            timeout: { type: 'number', describe: 'The timeout value in seconds to finish the query' },
            auth: { choices: ['basic'], describe: 'The type of authentication to use' },
            parseUnsupported: {
                type: 'boolean',
                describe: 'If no error should be emitted on unsupported versions',
                default: false,
            },
        })
            .check((arg) => {
            if (arg.auth === 'basic' && (!process.env.SPARQL_USERNAME || !process.env.SPARQL_PASSWORD)) {
                throw new Error('Basic authentication requires the SPARQL_USERNAME and SPARQL_PASSWORD environment variables.');
            }
            return true;
        })
            .version()
            .help('help')
            .parse();
        const queryString = yield getQuery(args.query, args.file);
        let defaultHeaders;
        if (args.auth === 'basic') {
            defaultHeaders = new Headers({
                authorization: `Basic ${Buffer.from(`${process.env.SPARQL_USERNAME}:${process.env.SPARQL_PASSWORD}`, 'binary').toString('base64')}`,
            });
        }
        const fetcher = new __1.SparqlEndpointFetcher({
            method: args.get ? 'GET' : 'POST',
            timeout: args.timeout ? args.timeout * 1000 : undefined,
            defaultHeaders,
            parseUnsupportedVersions: args.parseUnsupported,
        });
        const queryType = fetcher.getQueryType(queryString);
        switch (queryType) {
            case 'SELECT':
                yield querySelect(args.endpoint, fetcher, queryString);
                break;
            case 'ASK':
                yield queryAsk(args.endpoint, fetcher, queryString);
                break;
            case 'CONSTRUCT':
                yield queryConstruct(args.endpoint, fetcher, queryString);
                break;
            case 'UNKNOWN':
                if (fetcher.getUpdateTypes(queryString) !== 'UNKNOWN') {
                    yield update(args.endpoint, fetcher, queryString);
                }
                break;
        }
    });
}
run(process.argv).then().catch((error) => process.stderr.write(`${error.name}: ${error.message}\n${error.stack}`));
//# sourceMappingURL=fetch-sparql-endpoint.js.map